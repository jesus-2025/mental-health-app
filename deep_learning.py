{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMcau6kK75fUQUPJ16hliEh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"bytQpvYeO-Qj"},"outputs":[],"source":["import torch\n","import torch.optim as optim\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader, TensorDataset\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","\n","# Load dataset\n","df = pd.read_excel('/content/drive/My Drive/numerical_gender_mental_health_dataset.xlsx')\n","# Assuming you want to predict 'Depression State' (adjust if needed)\n","features = df.drop(['Depression State', 'Number'], axis=1).values # Remove 'Number' column\n","target = df['Depression State'].values\n","\n","# Scale features using StandardScaler\n","scaler = StandardScaler()\n","features = scaler.fit_transform(features)\n","\n","# Create TensorDataset\n","dataset = TensorDataset(torch.tensor(features, dtype=torch.float32),\n","                        torch.tensor(target, dtype=torch.long))\n","\n","# Split into train and validation sets\n","train_dataset, val_dataset = train_test_split(dataset, test_size=0.2, random_state=42)\n","\n","# Create DataLoaders\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=32)\n","\n","\n","# Define your model\n","class YourModel(nn.Module):\n","    def __init__(self, input_size, output_size):\n","        super(YourModel, self).__init__()\n","        self.fc1 = nn.Linear(input_size, 64)\n","        self.fc2 = nn.Linear(64, 32)\n","        self.fc3 = nn.Linear(32, output_size)  # Output layer with correct number of classes\n","\n","    def forward(self, x):\n","        x = torch.relu(self.fc1(x))\n","        x = torch.relu(self.fc2(x))\n","        return self.fc3(x)\n","\n","# Get the input size from your data\n","input_size = features.shape[1]  # Update if necessary\n","#output_size = len(df['Depression State'].unique())  # This was already defined before\n","model = YourModel(input_size, output_size).to(device)  # Pass both input_size and output_size\n","\n","# Define loss function and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","\n","\n","# Define training and validation functions\n","def train_epoch(model, data_loader, criterion, optimizer, device):\n","    model.train()\n","    running_loss = 0\n","    correct_preds = 0\n","    total_preds = 0\n","\n","    for batch in data_loader:\n","        inputs, labels = batch\n","        inputs, labels = inputs.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","\n","        # Convert outputs to class predictions\n","        _, predicted = torch.max(outputs.data, 1)\n","        correct_preds += (predicted == labels).sum().item()\n","        total_preds += labels.size(0)\n","\n","    avg_loss = running_loss / len(data_loader)\n","    accuracy = correct_preds / total_preds * 100\n","    return avg_loss, accuracy\n","\n","def validate_epoch(model, data_loader, criterion, device):\n","    model.eval()\n","    running_loss = 0\n","    correct_preds = 0\n","    total_preds = 0\n","\n","    with torch.no_grad():\n","        for batch in data_loader:\n","            inputs, labels = batch\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","\n","            running_loss += loss.item()\n","\n","            # Convert outputs to class predictions\n","            _, predicted = torch.max(outputs.data, 1)\n","            correct_preds += (predicted == labels).sum().item()\n","            total_preds += labels.size(0)\n","\n","    avg_loss = running_loss / len(data_loader)\n","    accuracy = correct_preds / total_preds * 100\n","    return avg_loss, accuracy\n","\n","# Setup for training\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Get the input size from your data\n","input_size = 18  # Update if necessary\n","#output_size = len(df['Depression State'].unique())  # This was already defined before\n","model = YourModel(input_size, output_size).to(device)  # Pass both input_size and output_size\n","\n","\n","criterion = nn.CrossEntropyLoss()  # Replace with your criterion\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","best_val_accuracy = 0\n","\n","# Training loop\n","epochs = 150\n","for epoch in range(epochs):\n","    # Train the model for one epoch\n","    train_loss, train_accuracy = train_epoch(model, train_loader, criterion, optimizer, device)\n","\n","    # Validate the model\n","    val_loss, val_accuracy = validate_epoch(model, val_loader, criterion, device)\n","\n","    # Save the model if validation accuracy improves\n","    if val_accuracy > best_val_accuracy:\n","        best_val_accuracy = val_accuracy\n","        torch.save(model.state_dict(), \"best_model.pth\")\n","        print(f\"âœ… Best model saved at epoch {epoch + 1}\")\n","\n","    # Print epoch summary\n","    print(f\"Epoch {epoch + 1}:\")\n","    print(f\"  Train Loss = {train_loss:.4f}, Train Accuracy = {train_accuracy:.4f}\")\n","    print(f\"  Validation Loss = {val_loss:.4f}, Validation Accuracy = {val_accuracy:.4f}\")\n","\n","# Load the best model after training is complete\n","model.load_state_dict(torch.load(\"best_model.pth\"))\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.ensemble import RandomForestClassifier  # Example classifier\n","from sklearn.metrics import accuracy_score\n","\n","# Example: Random Forest Classifier\n","model = RandomForestClassifier()\n","\n","# Define the parameter grid\n","param_grid = {\n","    'n_estimators': [100, 200, 300],\n","    'max_depth': [10, 20, 30],\n","    'min_samples_split': [2, 5, 10],\n","    'min_samples_leaf': [1, 2, 4]\n","}\n","\n","# Initialize GridSearchCV\n","grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='accuracy')\n","\n","# Fit grid search\n","grid_search.fit(X_train, y_train)\n","\n","# Best parameters and best accuracy score\n","best_params = grid_search.best_params_\n","best_score = grid_search.best_score_\n","\n","print(f\"Best Parameters: {best_params}\")\n","print(f\"Best Accuracy: {best_score}\")\n","# After training the model with the best parameters\n","best_model = grid_search.best_estimator_\n","\n","# Predict on the test set\n","y_pred = best_model.predict(X_test)\n","\n","# Calculate accuracy on test data\n","test_accuracy = accuracy_score(y_test, y_pred)\n","print(f\"Test Accuracy: {test_accuracy}\")\n"]}]}