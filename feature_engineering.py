{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOvhG2fxa1EOxgOCmTweASe"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356},"id":"BMCUBE1vN4lj","executionInfo":{"status":"error","timestamp":1746210024066,"user_tz":420,"elapsed":89,"user":{"displayName":"Nanthana Nanthana","userId":"18289594879093884258"}},"outputId":"eb88de25-9a69-4bf5-9090-e90b980a66ff"},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/content/drive/My Drive/final_converted_dataset.xlsx'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-8b619cdada3f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Load the existing preprocessed dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/final_converted_dataset.xlsx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Number of rows in the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m         io = ExcelFile(\n\u001b[0m\u001b[1;32m    496\u001b[0m             \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m   1548\u001b[0m                 \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xls\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1549\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1550\u001b[0;31m                 ext = inspect_excel_format(\n\u001b[0m\u001b[1;32m   1551\u001b[0m                     \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m                 )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1400\u001b[0m         \u001b[0mcontent_or_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_or_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1402\u001b[0;31m     with get_handle(\n\u001b[0m\u001b[1;32m   1403\u001b[0m         \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1404\u001b[0m     ) as handle:\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/final_converted_dataset.xlsx'"]}],"source":["import pandas as pd\n","import numpy as np\n","\n","# Load the existing preprocessed dataset\n","df = pd.read_excel('/content/drive/My Drive/final_converted_dataset.xlsx')\n","\n","# Number of rows in the dataset\n","num_rows = df.shape[0]\n","\n","# Add synthetic \"Age\" feature (random between 18 and 60)\n","df['Age'] = np.random.randint(18, 61, size=num_rows)\n","\n","# Add synthetic \"Gender\" feature (random choice)\n","df['Gender'] = np.random.choice(['Male', 'Female', 'Other'], size=num_rows)\n","\n","# Add synthetic \"Past_Mental_Health_History\" feature\n","df['Past_Mental_Health_History'] = np.random.choice(['Yes', 'No'], size=num_rows, p=[0.3, 0.7])  # 30% Yes, 70% No\n","\n","# Add synthetic \"Social_Support_Level\" feature (1 to 5 scale)\n","df['Social_Support_Level'] = np.random.randint(1, 6, size=num_rows)\n","\n","# Save the updated dataset\n","df.to_excel('/content/drive/My Drive/enhanced_dataset.xlsx', index=False)\n","\n","print(\"✅ New features added and dataset saved as 'enhanced_dataset.xlsx'\")\n","!pip install sdv\n","from sdv.single_table import CTGANSynthesizer\n","# Step 1: Install the latest SDV version\n","!pip install sdv --upgrade\n","\n","# Step 2: Import required libraries\n","import pandas as pd\n","from sdv.single_table import CTGANSynthesizer\n","from sdv.metadata import SingleTableMetadata\n","from sklearn.preprocessing import LabelEncoder\n","\n","# Step 3: Load your dataset\n","file_path = \"/content/drive/My Drive/enhanced_dataset.xlsx\"  # Update path if needed\n","df = pd.read_excel(file_path)\n","\n","# Step 4: Encode categorical columns\n","label_encoders = {}\n","for column in df.columns:\n","    if df[column].dtype == 'object':\n","        le = LabelEncoder()\n","        df[column] = le.fit_transform(df[column].astype(str))\n","        label_encoders[column] = le\n","\n","# Step 5: Create metadata\n","metadata = SingleTableMetadata()\n","metadata.detect_from_dataframe(data=df)\n","\n","# Step 6: Initialize and train CTGAN synthesizer\n","synthesizer = CTGANSynthesizer(metadata)\n","synthesizer.fit(df)\n","\n","# Step 7: Generate 1000 synthetic rows\n","synthetic_data = synthesizer.sample(1000)\n","\n","# Step 8: Decode label encoded columns\n","for column, le in label_encoders.items():\n","    synthetic_data[column] = le.inverse_transform(\n","        synthetic_data[column].clip(0, len(le.classes_) - 1).round().astype(int)\n","    )\n","\n","# Step 9: Combine original and synthetic data\n","extended_df = pd.concat([df, synthetic_data], ignore_index=True)\n","\n","# Step 10: Save the ex\n","\n","output_path =\"/content/drive/My Drive/extended_enhanced_dataset.xlsx\"\n","extended_df.to_excel(output_path, index=False)\n","\n","print(\"✅ Extended dataset saved at:\", output_path)\n","# Step 1: Install the latest SDV version\n","!pip install sdv --upgrade\n","\n","# Step 2: Import required libraries\n","import pandas as pd\n","from sdv.single_table import CTGANSynthesizer\n","from sdv.metadata import SingleTableMetadata\n","from sklearn.preprocessing import LabelEncoder\n","\n","# Step 3: Load your dataset\n","file_path = \"/content/drive/My Drive/enhanced_dataset.xlsx\"  # Update path if needed\n","df = pd.read_excel(file_path)\n","\n","# Step 4: Encode categorical columns in original data (if not already encoded)\n","label_encoders = {}\n","for column in df.columns:\n","    if df[column].dtype == 'object':\n","        le = LabelEncoder()\n","        df[column] = le.fit_transform(df[column].astype(str))\n","        label_encoders[column] = le\n","\n","# Step 5: Create metadata\n","metadata = SingleTableMetadata()\n","metadata.detect_from_dataframe(data=df)\n","\n","# Step 6: Initialize and train CTGAN synthesizer\n","synthesizer = CTGANSynthesizer(metadata)\n","synthesizer.fit(df)\n","\n","# Step 7: Generate 1000 synthetic rows\n","synthetic_data = synthesizer.sample(1000)\n","\n","# Step 8: Decode label encoded columns for synthetic data\n","for column, le in label_encoders.items():\n","    synthetic_data[column] = le.inverse_transform(\n","        synthetic_data[column].clip(0, len(le.classes_) - 1).round().astype(int)\n","    )\n","\n","# Step 9: Convert the \"Depression State\", \"Gender\", and \"Past_Mental_Health_History\" columns in synthetic data\n","# Assuming these columns were previously encoded in the range 0-3 for Depression State and 0-2 for Gender\n","# Map Depression State and Gender back to numerical values (e.g., Mild = 1, Moderate = 2, Severe = 3, None = 0)\n","depression_mapping = {'None': 0, 'Mild': 1, 'Moderate': 2, 'Severe': 3}\n","gender_mapping = {'Male': 1, 'Female': 2, 'Other': 3}\n","past_mental_health_history_mapping = {'Yes': 1, 'No': 0}\n","\n","# Apply mappings to synthetic data columns (you can adjust mappings if needed)\n","synthetic_data['Depression State'] = synthetic_data['Depression State'].map(depression_mapping)\n","synthetic_data['Gender'] = synthetic_data['Gender'].map(gender_mapping)\n","synthetic_data['Past_Mental_Health_History'] = synthetic_data['Past_Mental_Health_History'].map(past_mental_health_history_mapping)\n","\n","# Step 10: Combine original and synthetic data\n","extended_df = pd.concat([df, synthetic_data], ignore_index=True)\n","\n","# Step 11: Save the extended dataset\n","output_path = \"/content/drive/My Drive/extended_enhanced_dataset.xlsx\"\n","extended_df.to_excel(output_path, index=False)\n","\n","print(\"✅ Extended dataset saved at:\", output_path)\n","import pandas as pd\n","\n","# Load your dataset\n","file_path = \"/content/drive/My Drive/extended_enhanced_dataset.xlsx\"  # Update your dataset path\n","df = pd.read_excel(file_path)\n","\n","# Step 1: Change 'Number' column to be continuous from 1 to 1000\n","df['Number'] = range(1, len(df) + 1)\n","\n","# Step 2: Predict Depression State after 540 rows (assuming we already have Depression State for the first 540)\n","# You can use an if-else block or some heuristic model based on existing features to predict.\n","# Here, we will use a simple rule-based approach (you can modify it later as needed):\n","def predict_depression_state(row):\n","    if row['Sleep'] >= 4 and row['Fatigue'] >= 4:\n","        return 3  # Severe\n","    elif row['Interest'] <= 2 and row['Worthlessness'] >= 3:\n","        return 2  # Moderate\n","    elif row['Appetite'] >= 4 and row['Concentration'] >= 4:\n","        return 1  # Mild\n","    else:\n","        return 0  # None\n","\n","# Apply the depression prediction for rows after 540\n","df.loc[540:, 'Depression State'] = df.loc[540:].apply(predict_depression_state, axis=1)\n","\n","# Step 3: Convert `Depression State` to numerical format (already done above)\n","# 1 = Mild, 2 = Moderate, 3 = Severe, 0 = None\n","\n","# Step 4: Convert Gender to numerical format (Male = 1, Female = 2, Other = 3)\n","df['Gender'] = df['Gender'].map({'Male': 1, 'Female': 2, 'Other': 3})\n","\n","# Step 5: Convert Past Mental Health History to numerical format (Yes = 1, No = 0)\n","df['Past_Mental_Health_History'] = df['Past_Mental_Health_History'].map({'Yes': 1, 'No': 0})\n","\n","# Save the updated dataset to a new Excel file\n","output_path = \"/content/drive/My Drive/updated_extended_enhanced_dataset.xlsx\"\n","df.to_excel(output_path, index=False)\n","\n","print(\"✅ Dataset updated and saved successfully!\")\n","import pandas as pd\n","\n","# Step 1: Load the dataset\n","file_path = \"/content/drive/My Drive/extended_enhanced_dataset.xlsx\"  # Update the path if needed\n","df = pd.read_excel(file_path)\n","\n","# Step 2: Change 'Number' column to be continuous from 1 to 1000\n","df['Number'] = range(1, len(df) + 1)\n","\n","# Step 3: Predict Depression State after 540 rows (assuming we already have Depression State for the first 540)\n","# You can use an if-else block or some heuristic model based on existing features to predict.\n","# Here, we will use a simple rule-based approach (you can modify it later as needed):\n","def predict_depression_state(row):\n","    if row['Sleep'] >= 4 and row['Fatigue'] >= 4:\n","        return 3  # Severe\n","    elif row['Interest'] <= 2 and row['Worthlessness'] >= 3:\n","        return 2  # Moderate\n","    elif row['Appetite'] >= 4 and row['Concentration'] >= 4:\n","        return 1  # Mild\n","    else:\n","        return 0  # None\n","\n","# Apply the depression prediction for rows after 540\n","df.loc[540:, 'Depression State'] = df.loc[540:].apply(predict_depression_state, axis=1)\n","\n","# Step 4: Convert `Depression State` to numerical format (already done above)\n","# 1 = Mild, 2 = Moderate, 3 = Severe, 0 = None\n","\n","# Step 5: Convert Gender to numerical format (Male = 1, Female = 2, Other = 3)\n","df['Gender'] = df['Gender'].map({'Male': 1, 'Female': 2, 'Other': 3})\n","df['Gender'].fillna(0, inplace=True)  # For rows where gender is missing, assign 'Other' (value = 0)\n","\n","# Step 6: Convert Past Mental Health History to numerical format (Yes = 1, No = 0)\n","df['Past_Mental_Health_History'] = df['Past_Mental_Health_History'].map({'Yes': 1, 'No': 0})\n","df['Past_Mental_Health_History'].fillna(0, inplace=True)  # For rows where history is missing, assign 'No' (value = 0)\n","\n","# Step 7: Save the updated dataset to a new Excel file\n","output_path = \"/content/drive/My Drive/updated_extended_enhanced_dataset.xlsx\"  # Change this path if needed\n","df.to_excel(output_path, index=False)\n","\n","print(\"✅ Dataset updated and saved successfully!\")\n","import pandas as pd\n","\n","# Load the Excel file\n","df = pd.read_excel('/content/drive/My Drive/updated_extended_enhanced_dataset.xlsx')\n","\n","# Replace values in 'Gender' column\n","gender_mapping = {0: 'Female', 1: 'Male', 2: 'Others'}\n","df['Gender'] = df['Gender'].replace(gender_mapping)\n","\n","# Replace values in 'Past_Mental_Health_History' column\n","mental_health_mapping = {0: 'No', 1: 'Yes'}\n","df['Past_Mental_Health_History'] = df['Past_Mental_Health_History'].replace(mental_health_mapping)\n","\n","# Save the updated DataFrame to a new Excel file\n","df.to_excel('/content/drive/My Drive/final_updated_dataset.xlsx', index=False)\n","\n","print(\"✅ File saved successfully as 'final_updated_dataset.xlsx'\")\n","import pandas as pd\n","import random\n","\n","# Load the dataset\n","df = pd.read_excel('/content/drive/My Drive/final_updated_dataset.xlsx')\n","\n","# Randomly assign Gender values\n","df['Gender'] = [random.choice(['Male', 'Female', 'Others']) for _ in range(len(df))]\n","\n","# Randomly assign Past Mental Health History values\n","df['Past_Mental_Health_History'] = [random.choice(['Yes', 'No']) for _ in range(len(df))]\n","\n","# Show value counts to verify changes\n","print(df['Gender'].value_counts())\n","print(df['Past_Mental_Health_History'].value_counts())\n","\n","# Optional: Save the updated dataset\n","df.to_excel('/content/drive/My Drive/filled_gender_mental_health_dataset.xlsx', index=False)\n","import pandas as pd\n","\n","# Load the dataset\n","df = pd.read_excel('/content/drive/My Drive/filled_gender_mental_health_dataset.xlsx')\n","\n","# Convert Gender to numeric\n","gender_mapping = {'Male': 1, 'Female': 2, 'Others': 0}\n","df['Gender'] = df['Gender'].map(gender_mapping)\n","\n","# Convert Past_Mental_Health_History to numeric\n","mental_health_mapping = {'No': 0, 'Yes': 1}\n","df['Past_Mental_Health_History'] = df['Past_Mental_Health_History'].map(mental_health_mapping)\n","\n","# Show unique values to verify\n","print(df['Gender'].unique())\n","print(df['Past_Mental_Health_History'].unique())\n","\n","# Save the updated dataset\n","df.to_excel('/content/drive/My Drive/numerical_gender_mental_health_dataset.xlsx', index=False)\n"]}]}